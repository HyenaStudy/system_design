# 처리율 제한 장치 설계

## 1. 문제 상황 확인
1. 서버 측의 처리율 제한 장치(rate limiter, **이하 rl**)를 설계해야 한다
2. 처리율 제한 규칙은 유연해야 한다
3. 대규모 트래픽에도 견고해야 한다
4. 분산 환경에서 동작해야 한다
5. 예외 처리가 필요하다

## 2. 구현 전제 조건
### (1) 직접 구현할 경우 - JVM 계열 언어가 적합한가?
**rl의 매커니즘은 동기/비동기, 블로킹/논블로킹을 고려하지 않는다**
- I/O 요청의 동기/비동기 처리나, 핸들러의 블로킹/논블로킹 여하에 관련없이 rl은 입장 허용 여부만 판별
- 매장 오픈 전 문 앞 손님들이 질서있게 있든, 마구잡이로 몰려있든 매장 입구컷의 적용은 동일한 것처럼

**JVM은 원자적 연산(CAS)에 매우 강력하다**
- rl은 대부분 원자적 카운팅(증감 연산) 기반의 알고리즘
- `Atomic` 시리즈, `Lock` 인터페이스 구현체, `Concurrent` 시리즈처럼 원자 연산을 지원하는 자료구조가 풍부함

**서버 아키텍처의 확장에 구애받지 않는다: 대규모 트래픽에도 견고한 rl 세팅 가능**
- 모놀리스라면 Spring MVC의 필터나 인터셉터 단에 자연스럽게 세팅 가능
- 분산 마이크로서비스로 확장하면 Spring Cloud의 API Gateway에 세팅하는 것 또한 가능
- 다만 스케일 아웃으로 분산 환경까지 다다르면 직접 구현만 하지 않고 외부 서비스와 결합된 rl 세팅이 더 자연스러워질 것

### (2) 외부 서비스를 빌릴 경우 - 선택 기준이 무엇인가?
**1번 고려사항과 2번 고려사항 일부분의 충돌**
- rl의 선택 기준은 **적용 위치**(엣지, 앱 내부)와 **적용 OSI 7계층**(L4, L7)
- 엣지는 CDN과 같이 클라이언트와 밀접한 영역에 rl을 세팅하는 것
- 현재 문제 상황의 **서버 측 설계**에 부합하지 않으므로 rl은 **앱 내부**에 세팅해야 한다
- 즉, **API 중심 처리율 제한 정책**을 적용할 것이므로 CDN 기반 rl, DDos 방어 기반 rl은 선택 논외사항
- 앱 내부를 기준으로 **적용 OSI 계층은 L7에 한정**된다. 즉 API 중심이 되므로 패킷 정보와 같은 처리율 제한 기준 폭이 줄어든다
- 하지만, **API 요청의 IP, 헤더 정보, 엔드포인트 혹은 메소드 등 충분히 다양한 기준을 충족**할 수 있음
- 그러므로 Cloudflare 같은 엣지 기반 rl 서비스는 배제

**서버의 환경 고려**
- 4번 고려사항에 따라 서버는 분산 환경을 상정하게 됨
- 모놀리스는 rl 배치 레이어 선택지가 적은 편
  - 필터, 인터셉터 : `Bucket4j`
  - 컨트롤러
  - AOP
  - 프록시 서버(외부 rl 가능) : `NGINX Plus`
- 분산 환경(MSA)까지 나아가면 rl 배치 레이어 선택지는 다양하게 늘어남
  - API Gateway : `Spring Cloud Gateway` + `Bucket4j`
  - 서비스 메쉬(서비스 간 네트워크, 서비스 간 호출량 제한) : `Istio`
  - 사이드카(서비스 개별 프록시, 각 서비스별 처리율 제한 정책) : `Envoy` + `Redis`
  - 기존 인 서비스 레이어

## 3. 처리율 제한 알고리즘
- 버킷 기반이든 윈도우 기반이든 요청은 모여서 일괄 처리되지 않고 조건만 맞으면 바로 통과되며 카운터만 올라감
- 보통 미들웨어가 곧 알고리즘 배치 레이어고, 분산 환경에서는 원자적 연산을 위해 외부 카운터(Redis 같은)를 두는 편
- 단, 외부 서비스들은 이미 내부적으로 원자적 연산 카운터를 갖고 있음
### (1) 토큰 버킷(token bucket)
0. 파라미터는 **버킷 사이즈**와 **초당 토큰 공급률(refill rate)**
1. 버킷에 토큰이 덜 채워지면 공급되고, 다 채워진 버킷에 공급되는 토큰은 버려짐(overflow)
2. 요청 처리당 토큰 하나가 소모되고, 토큰이 없는데 들어온 처리 요청은 버려짐(dropped)
### (2) 누출 버킷(leaky bucket)
0. 파라미터는 **버킷(큐) 사이즈**와 **처리율(outflow rate: 지정된 시간당 항목 처리 개수)**
1. 큐는 처리율에 따라 지정된 시간당 정해진 요청을 처리하고 해당 개수만큼 pop
2. 요청이 도달했을 때, 큐가 비어있으면 채워지고 큐가 가득 차있으면 요청은 버려짐
### (3) 고정 윈도우 카운터(fixed window counter)
0. 시간선을 일정한 **간격(window)** 으로 나누고, 각 윈도우마다 **요청 카운터** 부여
1. 윈도우가 유지되는 동안(해당 간격의 시간이 흐르는 동안) 요청이 접수되면 카운팅
2. 해당 간격의 시간이 다 흐르면 새로운 윈도우가 열리고, 카운터가 임계치일 때 들어온 요청은 버려짐
3. 사실상 윈도우와 윈도우 간 경계에 트래픽이 몰리면 임계치 2배의 처리량을 갖는 단점
### (4) 이동 윈도우 로그(sliding window log)
0. 파라미터는 **시간 간격(T)** 와 **허용 요청수(L)**
1. 요청의 타임스탬프는 처리 여부와 무관하게 로그로 기록된다
2. 요청을 기준으로 T만큼 역으로(`요청 타임스탬프 - T ~ 요청 타임스탬프`) 타임스탬프 로그를 카운팅한다
3. 로그 카운트가 L이면 해당 요청은 무시된다
4. 로그 카운트가 L 미만이면 해당 요청은 처리된다
5. 탐색 기준으로 `요청 타임스탬프 - T` 이전의 타임스탬프 로그는 전부 삭제(만료 처리)된다
6. 덕분에 고정 윈도우의 경계 폭발 문제 커버 but 로그를 전부 기록하므로 메모리 효율이 떨어짐
### (5) 이동 윈도우 카운터(sliding window counter)
0. 파라미터는 **시간 간격(T)** 와 **허용 요청수(L)**, **버킷 사이즈(b, T를 일정 비율로 분할한 범위)**
1. 요청을 기준으로 T만큼 역으로(`요청 타임스탬프 - T ~ 요청 타임스탬프`) 탐색
2. `total count = 현재 b의 요청 카운트 + 직전 b의 요청 카운트 * (현재 b 기준 경과 시간 / b 시간)`
3. `total count`가 L보다 작으면 요청이 처리된다
4. 버킷별 카운트만 저장하면 돼서 이동 윈도우 로그보다 메모리 효율이 나은 편

## 4. 분산 환경 고려
### (1) 카운터의 경쟁 조건, 동기화 이슈
- 보통 카운터는 **Redis**를 많이 쓰는 편
- Redis의 동작 매커니즘은 싱글 스레드지만 복잡한 로직은 단일 명령으로는 부족해서 경쟁 조건 발생 가능성
- `ZSET` 자료구조나 루아 스크립트를 통해 원자적 연산 보장(경쟁 조건 극복)
- 처리율 제한 알고리즘 서버를 여러 개 두면서 Redis는 중앙 집중형 카운터로 1개만 두기(동기화 이슈 극복)
- Redis 싱글 스레드 특성상 대규모 트래픽에 취약할 수 있으니 샤딩/파티셔닝이나 Redis Cluster 고려
### (2) 성능 최적화: 엣지 서버별 로컬 rl 정책 + 글로벌 카운터
- 데이터 센터 중, 클라이언트와 지리적으로 가까운 엣지 서버로 라우팅
- 엣지 서버에 한정하여 rl 처리하므로 성능 최적화 가능
**최종 일관성 모델 적용: 엣지 서버의 rl 정책과 글로벌 카운터의 토큰 분배량**
- 엣지 서버의 rl 정책은 철저히 보수적으로 동작한다
- 다만 엣지 서버의 처리량은 로컬 임계치와 무관하게 글로벌 카운터의 여유에 따라 달라짐
- 엣지 서버의 rl 동작은 우선 엣지 서버 내부적으로 처리되고(선조치), 글로벌 카운터에 추후 반영(후보고)됨
- 글로벌 카운터의 상태에 따라 엣지 서버의 **토큰량(quota)** 이 조정됨
  - 글로벌 여유가 충분하면 엣지 토큰량은 로컬 임계치까지 회복 가능
  - 글로벌 여유가 없으면 엣지 토큰량은 제한되어 요청이 거부될 수 있음
- 엣지 서버의 로컬 임계치는 고정되며 정책 값, 글로벌 카운터와 직접 연동되지는 않음
- 글로벌 카운터 갱신 시점에 따라 엣지 토큰량도 부분적으로 초기화되거나 회복됨
- 이를 통해 엣지에서 빠른 응답 처리를 보장하면서도, 최종적으로 글로벌 처리율 제한을 준수함
- 요약하자면, 엣지의 로컬 임계치는 최후 마지노선이고 평소에는 글로벌 카운터의 토큰 분배량에 따라 처리

## 5. 결론
### (1) 알고리즘
- 분산 환경과 대규모 트래픽을 고려했을 때, 알고리즘은 슬라이딩 윈도우 카운터를 채택
- 직접 구현하는 게 더 적합할듯? 라이브러리가 없는데
- Java 컬렉션 + Redis 중앙 집중 카운터
- API 요청별 IP 기반으로 타임스탬프 로그
### (2) 배치 레이어
- 배치 레이어는 서비스의 개수가 적으면 **사이드카**, 많으면 **API Gateway**
- 서비스 규모가 더 확장되면 엣지 서버별 로컬 카운터를 두고 최종 일관성 모델 점진적 적용
### (3) 장애 대응
- 각 서비스 rl별 카운트 여유분 모니터링 & 로깅
- Redis 센티넬 적용 혹은 규모 확장시 클러스터링까지
